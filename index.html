<!DOCTYPE html>
<html>
  <head>
    <title>ECE M202A Project</title>
  </head>
  <body>
    <h1 style="text-align: center; font-size: 40px;">
      <b>Head Pose Estimation using Earables</b>
    </h1>
    <h2>Project Summary</h2>
    <p>Objective:</p>
    <p>
      <br><br><br>
      The goal of this project is to estimate the head-pose using IMU information collected from Nokia’s eSense earables and use the estimated head-pose to create and show animojis for users on an android device.
    </p>
    <p>Envisioned approach:</p>
    <p>
      <br>
      First, we record facial videos and IMU information at the same time and then we generate ground truth tables using the videos with matured head-pose estimation algorithm. We plan to build head-pose estimation model using collected IMU information as training data and previously generated ground truth tables as the label of training data. We plan to use CNN (Convolutional Neural Network) to train the model. At the end, we will implement an android app to show animojis of users just using IMU information.
    </p>
    <p>Planned deliverables:</p>
    <ul>
      <li>Collected sample data: facial recordings and IMU information</li>
      <li>Ground truth tables generated from facial recordings</li>
      <li>CNN model for head-pose estimation</li>
      <li>Android app to create and show animojis for users</li>
    </ul>
    <p>Rough timeline:</p>
    <ul>
      <li>Week 4 – 6.5: Collecting sample data and generate ground truth tables</li>
      <li>Week 6.5 – 8: Train the CNN model for head-pose estimation</li>
      <li>Week 9– 10: implement the android app for animojis</li>
    </ul>
    <p>Work distribution:</p>
    <ul>
      <li>Collect sample data & generate ground truth table: Yuanyuan Xiang (50%), Qiuyang Yue (50%)</li>
      <li>CNN model for head pose estimation: Yuanyuan Xiang (60%), Qiuyang Yue (40%)</li>
      <li>Develop an Android app: Qiuyang Yue (60%), Yuanyuan Xiang (40%)</li>
    </ul>
  </body>
<html>
